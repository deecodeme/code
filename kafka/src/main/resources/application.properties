kafka.producer.bootstrap.servers=localhost:9092
kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer

# Logical identifier of the Application,a meaningful to be used to be helpful in debugging like the service name
kafka.producer.client.id=test-servicekafka.producer

# Ack
# acks required from partition leader and replicas. '0' being no ack, '1' being leader ack and 'all' being the ack from leader+replicas
# producer latency will be higher with more reliable acks. However, end-to-end latency will not differ as,
# Kafka makes the message available to consumers only if the message is replicated to all in sync replicas
kafka.producer.acks=all

# Message Delivery Time
# Time taken to send() + time to get callback()
# max.block.ms is to specify, how long a producer may block when calling send(), this is where Producer adds the record to a batch of the partition
# A timeout exception is thrown if time exceeds
kafka.producer.max.block.ms=1000

# To limit the amount of time spent from the point a record was added into a batch and until the broker responds or client gives up including retries.
# Callback will be called with either a timeout exception or exception with error from broker before retrying.
# An ideal value would be 120,000 which can cover for leader election which takes around 30 seconds to complete.
# Broker can do any number of retries during that time.
# this time should be greater than linger.ms + retry.backoff.ms + request.timeout.ms as this includes for all.
# It is recommended to use delivery.timeout.ms to control the overall timeout.
# It is also a good practice to test leader re-election time on your broker setup and set this value to not give up early.
# kafka.producer.delivery.timeout.ms=

# timeout to wait for a response from server. On Timeout, Producer may retry or callback with TimeoutException
# kafka.producer.request.timeout.ms=

# Producer's back off time between two retries, default 100 ms
# kafka.producer.retry.backoff.ms=

# time to wait for the batch to be sent to the server. KafkaProduce sebd the batch if the current batch is full or time exceeds linger.ms.
# By default, Kafka sends the current batch as soon as the sender thread is free.
# Setting linger.ms to greater than 0, increases throughput significantly with little increase in latency.
kafka.producer.linger.ms=10

# limit the number of retries to. Set the value to 0 to disable retries completely
# kafka.producer.retries=

# amount of memory producer will use to buffer messages waiting to be sent to brokers. The producer may run out of space,
# if Application is producing faster than messages being delivered to the server. I
# n that case producer will block send() for max of max.block.ms waiting for space to free up before throwing exception.
#kafka.producer.buffer.memory=

# By default, messages are sent uncompressed. Enabling compression can reduce network utilization and storage, which is often the bottleneck
# Compression algorithm can be set to snappy/gzip/lz4/zstd.
# Snappy, invented by google provides decent compression ratio with low CPU overhead and good performance, hence recommended where both performance and bandwidth are a concern.
# gzip proves better compression ratio but use more CPY, typically used in cases where network bandwidth is more restricted.
kafka.producer.compression.type=snappy

# Amount of memory in bytes which can be used to keep messages in a batch
# Producer will send the batch if it is full, Kafka producer will send the message as soon as batch sending thread is free, even with single message or batch half full.
# Therefore, setting large batch size will not cause delay in sending messages. It would just use more memory for batches.
# Setting it too small would cause overhead of sending more frequently.
#kafka.producer.batch.size=

# This controls how many requests(batches) KafkaProducer will send without sending response.
# Higher settings can increase memory usage while improving throughput.
# Default value is 5, and it is optimum for single DC.
# gotcha: Setting this parameter to > 1 with retries > 0 can result in non-ordering of messages.
# If used together, it should be used with enable.idempotence=true to maintain the ordering guarantee and avoid duploication.
kafka.producer.max.in.flight.requests.per.connection=5

# control the size of produce request(batch).
# It caps both, size of the largest message that can be sent and the number of the messages KafkaProducer cans end in one request
# With 1 MB limit, KafkaProducer could either produce 1 batch with a message of 1 MB or 1 batch with 1024 messages of 1 KB size.
# gotcha: Broker also has a limit on the message size, message.max.bytes. Configuration should be matched between Producer and Broker.
# Default value 1024*1024
kafka.producer.max.request.size=1024000

# size of the TCP send and receive buffers used by the socket when writing and reading data.
# If these will be set to -1, OS defaults will be used. It is good idea to increase these when producer or consumer communicate with brokers in a different datacenter,
#  because those networks links typically have higher latency and lower bandwidth
# default value 32*1024
kafka.producer.receive.buffer.bytes=32768

# Default value 128 * 1024
kafka.producer.send.buffer.bytes=131072

# to enable idempotent producer
# with improved reliability with acks=all and retries>0 and large delivery.timeout.ms can give you a guarantee of at-least-once, but it can do more than once too.
# If enable KafkaProducer attaches a sequence number with each record it sends, if broker finds a duplicate sequence number, Producer will receive DuplicateSequenceException
# gotcha: Enabling, requires max.in.flight.requests.per.connection < 5, retries > 0 and acks=all
kafka.producer.enable.idempotence=true


